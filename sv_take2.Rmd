---
title: "SV Exploration"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(countrycode)
library(janitor)
library(rstatix)
library(splines)
theme_set(theme_bw())
```

I am going to take all of Nico's cleaning code.

```{r}
load("Data/wvs_timeseries.rdata")

d <- data1 %>% 
  haven::zap_labels()

rm(data1)

d_short <- d %>% 
  select(S002VS, 
         COUNTRY_ALPHA,
         S020,
         S003,
         X001,
         X003, 
         X007, 
         F118:F123, 
         A124_06) %>% 
  rename(wave = S002VS, 
         country = COUNTRY_ALPHA,
         country_code = S003, 
         year_survey = S020,
         sex = X001,
         age = X003, 
         marital_status = X007, 
         just_homosexuality = F118, 
         just_prostitution = F119, 
         just_abortion = F120, 
         just_divorce = F121, 
         just_euthanasia = F122, 
         just_suicide = F123, 
         neigh_imm = A124_06) 

d_short <- d_short %>% 
  mutate(
    across( 
      .cols = 6:14, # changed to include age and marital status
       ~ ifelse(
        . < 0, 
        NA_real_, 
        .
      ))
  )

summary_df <- d_short %>% 
  select(country,
         wave,
         8:14) %>% 
  pivot_longer(3:9, 
               names_to = "variable", 
               values_to = "response") %>% 
  mutate(valid_response = if_else(
    is.na(response),0, 1
  )) %>% 
  group_by(
    country, 
    wave, 
    variable
  ) %>% 
  summarise(
    count = sum(valid_response)
  ) %>% 
  ungroup()

```

I want to see start and end dates for individual questions in each country and the number of waves. This tells us how long the series is in that country for that question and how many distinct waves. 

NOTE: I am also going to make a few new variables:
- `age01` is (age-18)/(64-18) (makes interpretation a bit easier)
- `birthyear` (we will use more versions of this later)
- `cohort10` (coarsened by 10s)

```{r}
d_waves <- d_short %>% 
  pivot_longer(just_homosexuality:neigh_imm,
               names_to = "variable",
               values_to = "y") %>%
  mutate(age01 = (age - 18)/(64 - 18),
         birthyear = year_survey - age,
         cohort10 = floor(birthyear/10) * 10) %>%  # CHANGED TEMP
  drop_na() %>% 
  group_by(country, variable) %>% 
  mutate(start = min(year_survey),
         end = max(year_survey),
         span = end - start,
         waves = n_distinct(wave),
         obs = n()) %>% 
  ungroup()
```

Keep country/variables where we have at least 4 waves over 30 years. Only use people who are 25 and above.

```{r}
d30 <- d_waves %>% 
  filter(waves >= 4 & span >= 30 & age > 24)

table(d30$country, d30$variable)
```

This might be good enough: 8 countries and in different areas of the world. I'm going to do "1930 and earlier" and "1980 and later" on the ends of both variables. We might revisit this later.

```{r}
d30 <- d30 %>% 
  mutate(
    cohort10b = factor(
      case_when(
        cohort10 < 1930 ~ 1930,
        cohort10 > 1980 ~ 1980,
        TRUE ~ cohort10
      )
    )
  )
```

We are now ready to nest the df.

```{r}
d30_nest <- d30 %>% 
  group_by(country, variable) %>% 
  nest()
```


We can use FE ANOVA to get an approximation of the "delta" statistic that Omar and I use to calculate cultural durability. We could choose different coarsenings in the final version but I will use `cohort10b` here for simplicity.

Let's try getting deltas for all countries.

First the function.

```{r}
get_delta <- function(df) {
  fe1 <- lm(y ~ age01 + I(age01^2) + cohort10b + factor(year_survey),
            data = df)
  
  at <- anova_test(fe1, detailed = TRUE)
  
  C_mse <- at[3,2] / at[3,4]
  P_mse <- at[4,2] / at[4,4]
  
  Delta <- C_mse / (C_mse + P_mse)
  return(Delta)
}
```

Now nest and map

```{r}
d30_results <- d30_nest %>% 
  mutate(delta = map_dbl(data, get_delta)) %>% 
  select(country, variable, delta)

glimpse(d30_results)

hist(d30_results$delta)

d30_results %>% 
  ungroup() %>% 
  summarize(med = median(delta),
            min = min(delta),
            max = max(delta),
            .by = country) %>% 
  arrange(med)
```

### EXPERIMENTAL ####

Test some new stuff (splines instead of dummies)

```{r, eval=FALSE}
dt <- d30_nest[22,] %>% unnest(cols = "data")

# alt delta (doesn't work)
get_delta2 <- function(df) {
  fe1 <- lm(y ~ ns(age01, df = 2) + ns(birthyear, df = 3) + ns(year_survey, df = 3),
            data = df)
  
  at <- anova_test(fe1, detailed = TRUE)
  
  C_sse <- at[2,2] / at[2,4]
  P_sse <- at[3,2] / at[3,4]
  
  Delta <- C_sse / (C_sse + P_sse)
  return(Delta)
}

# alt delta
get_delta3 <- function(df) {
  fe1 <- lm(y ~ ns(age01, df = 2) + cohort10b + factor(year_survey),
            data = df)
  
  at <- anova_test(fe1, detailed = TRUE)
  
  C_sse <- at[2,2] / at[2,4]
  P_sse <- at[3,2] / at[3,4]
  
  Delta <- C_sse / (C_sse + P_sse)
  return(Delta)
}

d30_results_alt <- d30_nest %>% 
  mutate(delta = map_dbl(data, get_delta3)) %>% 
  select(country, variable, delta)

glimpse(d30_results_alt)

hist(d30_results_alt$delta)

d30_results_alt %>% 
  ungroup() %>% 
  summarize(med = median(delta),
            min = min(delta),
            max = max(delta),
            .by = country) %>% 
  arrange(med)


d30 %>% 
  filter(country == "AUS" & variable == "just_prostitution") %>% 
  group_by(cohort10b,
           year_survey) %>% 
  summarize(y = mean(y)) %>%
  ggplot(aes(x = year_survey,
             y = y,
             group = cohort10b,
             color = cohort10b)) +
  geom_point() +
  geom_line()

```

